# Awesome-Autoregressive-Visual-Generation

## Speech/Audio Tokenizers

1. SoundStream: An End-to-End Neural Audio Codec [Paper](https://arxiv.org/pdf/2107.03312)
2. HIFI-CODEC: GROUP-RESIDUAL VECTOR QUANTIZATION FOR HIGH FIDELITY AUDIO CODEC [Paper](https://arxiv.org/pdf/2305.02765)
3. Self-Supervised Learning with Random-Projection Quantizer for Speech Recognition [Paper](https://arxiv.org/pdf/2202.01855)
4. WaveNet: A Generative Model for Raw Audio [Paper](https://arxiv.org/pdf/1609.03499)

## Image Tokenizers

1. Neural Discrete Representation Learning [Paper](https://arxiv.org/abs/1711.00937)
2. Generating Diverse High-Fidelity Images with VQ-VAE-2 [Paper](https://arxiv.org/abs/1906.00446)
3. Autoregressive Image Generation using Residual Quantization [Paper](https://arxiv.org/pdf/2203.01941)
4. BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers [Paper](https://arxiv.org/pdf/2208.06366)
5. Vector-quantized Image Modeling with Improved VQGAN [Paper](https://arxiv.org/pdf/2110.04627)
6. MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation [Paper](https://arxiv.org/abs/2209.09002)
7. PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers [Paper](https://arxiv.org/pdf/2111.12710)
8. All in Tokens: Unifying Output Space of Visual Tasks via Soft Token [Paper](https://arxiv.org/pdf/2301.02229)
9. Regularized Vector Quantization for Tokenized Image Synthesis [Paper](https://arxiv.org/pdf/2303.06424)
10. Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization [Paper](https://arxiv.org/pdf/2305.11718)
11. HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes [Paper](https://arxiv.org/pdf/2401.00365)
12. Taming Transformers for High-Resolution Image Synthesis [Paper](https://arxiv.org/pdf/2012.09841)
13. Finite Scalar Quantization: VQ-VAE Made Simple [Paper](https://arxiv.org/abs/2309.15505)
14. Not all image regionsmatter: Masked vector quantization for autoregressive image generation [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.pdf), CVPR 2023
15. Conditional image generation with pixelcnn decoders [Paper](https://proceedings.neurips.cc/paper_files/paper/2016/file/b1301141feffabac455e1f90a7de2054-Paper.pdf), NeurIPS 2016
16. Planting a seed of vision in large language model [Paper](https://openreview.net/pdf?id=0Nui91LBQS), ICLR 2024
17. Towards accurate image coding: Improved autoregressive image generation with dynamic vector quantization [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.pdf), CVPR 2023
18. Spae: Semantic pyramid autoencoder for multimodal generation with frozen llms [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/a526cc8f6ffb74bedb6ff313e3fdb450-Paper-Conference.pdf), NeurIPS 2023
19. Language model beats diffusionâ€“tokenizer is key to visual generation [Paper](https://openreview.net/pdf?id=gzqrANCF4g), ICLR 2024
20. Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction [Paper](https://arxiv.org/abs/2404.02905), Arxiv 2024
21. An Image is Worth 32 Tokens for Reconstruction and Generation[Paper](https://arxiv.org/pdf/2406.07550), Arxiv 2024
22. 


## Image Generator (Non-diffusion)

1. DiVAE : Photorealistic Images Synthesis with Denoising Diffusion Decoder [Paper](https://arxiv.org/pdf/2206.00386)
2. Vector Quantized Diffusion Model for Text-to-Image Synthesis [Paper](https://arxiv.org/pdf/2111.14822)
3. MaskGIT: Masked Generative Image Transformer [Paper](https://arxiv.org/pdf/2202.04200)
4. BEIT: BERT Pre-Training of Image Transformers [Paper](https://arxiv.org/pdf/2106.08254)
5. BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers [Paper](https://arxiv.org/pdf/2208.06366)
6. MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis [Paper](https://arxiv.org/pdf/2211.09117)
7. Sequential modeling enables scalable learning for large vision models [Paper](https://arxiv.org/abs/2312.00785), Arxiv 2023
8.  4m: Massively multimodal masked modeling [Paper](https://openreview.net/pdf?id=TegmlsD8oQ), NeurIPS 2023
9.  Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation [Paper](https://arxiv.org/abs/2406.06525), NeurIPS 2023
