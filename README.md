# Awesome-Autoregressive-Visual-Generation
This is a repo to track the latest autoregressive visual generation papers.

## Image Tokenizers
1. Neural Discrete Representation Learning [Paper](https://arxiv.org/abs/1711.00937), NeurIPS 2017
2. Generating Diverse High-Fidelity Images with VQ-VAE-2 [Paper](https://arxiv.org/abs/1906.00446), NeurIPS 2019
3. Taming Transformers for High-Resolution Image Synthesis [Paper](https://arxiv.org/pdf/2012.09841), CVPR 2021
4. Autoregressive Image Generation using Residual Quantization [Paper](https://arxiv.org/pdf/2203.01941), CVPR 2022
5. \* BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers (for understanding) [Paper](https://arxiv.org/pdf/2208.06366), Arxiv 2022
6. Vector-quantized Image Modeling with Improved VQGAN [Paper](https://arxiv.org/pdf/2110.04627), ICLR 2022
7. MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation [Paper](https://arxiv.org/abs/2209.09002), NeurIPS 2022
8. \* PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers (for understanding) [Paper](https://arxiv.org/pdf/2111.12710), AAAI 2023
9. \* All in Tokens: Unifying Output Space of Visual Tasks via Soft Token (for understanding) [Paper](https://arxiv.org/pdf/2301.02229), CVPR 2023
10. Regularized Vector Quantization for Tokenized Image Synthesis [Paper](https://arxiv.org/pdf/2303.06424), CVPR 2023
11. Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization [Paper](https://arxiv.org/pdf/2305.11718), CVPR 2023
12. Not all image regionsmatter: Masked vector quantization for autoregressive image generation [Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.pdf), CVPR 2023
13. Spae: Semantic pyramid autoencoder for multimodal generation with frozen llms [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/a526cc8f6ffb74bedb6ff313e3fdb450-Paper-Conference.pdf), NeurIPS 2023
14. HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes [Paper](https://arxiv.org/pdf/2401.00365), TMLR 2024
15. Finite Scalar Quantization: VQ-VAE Made Simple [Paper](https://arxiv.org/abs/2309.15505), ICLR 2024
16. Planting a seed of vision in large language model [Paper](https://openreview.net/pdf?id=0Nui91LBQS), ICLR 2024
17. Language model beats diffusionâ€“tokenizer is key to visual generation [Paper](https://openreview.net/pdf?id=gzqrANCF4g), ICLR 2024
18. Rethinking the Objectives of Vector-Quantized Tokenizers for Image Synthesis [Paper](https://arxiv.org/abs/2212.03185), CVPR 2024
19. Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction [Paper](https://arxiv.org/abs/2404.02905), Arxiv 2024
20. An Image is Worth 32 Tokens for Reconstruction and Generation [Paper](https://arxiv.org/pdf/2406.07550), Arxiv 2024
21. Scaling the Codebook Size of VQGAN to 100,000 with a Utilization Rate of 99% [Paper](https://arxiv.org/pdf/2406.11837), Arxiv 2024
22. Quantised Global Autoencoder: A Holistic Approach to Representing Visual Data [Paper](https://arxiv.org/pdf/2407.11913), Arxiv 2024

## AutoRegressive Image Generation

1. Conditional image generation with pixelcnn decoders [Paper](https://proceedings.neurips.cc/paper_files/paper/2016/file/b1301141feffabac455e1f90a7de2054-Paper.pdf), NeurIPS 2016
2. DiVAE : Photorealistic Images Synthesis with Denoising Diffusion Decoder [Paper](https://arxiv.org/pdf/2206.00386)
3. Vector Quantized Diffusion Model for Text-to-Image Synthesis [Paper](https://arxiv.org/pdf/2111.14822)
4. MaskGIT: Masked Generative Image Transformer [Paper](https://arxiv.org/pdf/2202.04200)
5. BEIT: BERT Pre-Training of Image Transformers [Paper](https://arxiv.org/pdf/2106.08254)
6. BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers [Paper](https://arxiv.org/pdf/2208.06366)
7. MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis [Paper](https://arxiv.org/pdf/2211.09117)
8. Sequential modeling enables scalable learning for large vision models [Paper](https://arxiv.org/abs/2312.00785), Arxiv 2023
9. 4m: Massively multimodal masked modeling [Paper](https://openreview.net/pdf?id=TegmlsD8oQ), NeurIPS 2023
10. Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation [Paper](https://arxiv.org/abs/2406.06525), Arxiv 2024
11. ControlVAR: Exploring Controllable Visual Autoregressive Modeling [Paper](https://arxiv.org/pdf/2406.09750), Arxiv 2024
12. Autoregressive Image Generation without Vector Quantization [Paper](https://arxiv.org/pdf/2406.11838), Arxiv 2024
13. MARS: Mixture of Auto-Regressive Models for Fine-grained Text-to-image Synthesis  [Paper](https://arxiv.org/pdf/2407.07614), Arxiv 2024
14. ANOLE: AnOpen,Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation [Paper](https://arxiv.org/pdf/2407.06135v1), Arxiv 2024
15. VAR-CLIP: Text-to-Image Generator with Visual Auto-Regressive Modeling [Paper](https://arxiv.org/abs/2408.01181), Arxiv 24
16. Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining [Paper](https://www.arxiv.org/abs/2408.02657), Arxiv 24
17. Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model [Paper](https://arxiv.org/pdf/2408.11039), Arxiv 2024
18. Scalable Autoregressive Image Generation with Mamba [Paper](https://arxiv.org/abs/2408.12245), Arxiv 2024
19. SHOW-O: ONE SINGLE TRANSFORMER TO UNIFY MULTIMODAL UNDERSTANDING AND GENERATION [Paper](https://showlab.github.io/Show-o/assets/show-o.pdf), Arxiv 2024
    
