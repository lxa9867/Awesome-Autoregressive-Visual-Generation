# Awesome-Autoregressive-Visual-Generation

## Image Tokenizers

1. Neural Discrete Representation Learning [Paper](https://arxiv.org/abs/1711.00937)
2. Generating Diverse High-Fidelity Images with VQ-VAE-2 [Paper](https://arxiv.org/abs/1906.00446)
3. Autoregressive Image Generation using Residual Quantization [Paper](https://arxiv.org/pdf/2203.01941)
4. BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers [Paper](https://arxiv.org/pdf/2208.06366)
5. Vector-quantized Image Modeling with Improved VQGAN [Paper](https://arxiv.org/pdf/2110.04627)
6. MoVQ: Modulating Quantized Vectors for High-Fidelity Image Generation [Paper](https://arxiv.org/abs/2209.09002)
7. PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers [Paper](https://arxiv.org/pdf/2111.12710)
8. All in Tokens: Unifying Output Space of Visual Tasks via Soft Token [Paper](https://arxiv.org/pdf/2301.02229)
9. Regularized Vector Quantization for Tokenized Image Synthesis [Paper](https://arxiv.org/pdf/2303.06424)
10. Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization [Paper](https://arxiv.org/pdf/2305.11718)
11. HQ-VAE: Hierarchical Discrete Representation Learning with Variational Bayes [Paper](https://arxiv.org/pdf/2401.00365)
12. SoundStream: An End-to-End Neural Audio Codec [Paper](https://arxiv.org/pdf/2107.03312)
13. HIFI-CODEC: GROUP-RESIDUAL VECTOR QUANTIZATION FOR HIGH FIDELITY AUDIO CODEC [Paper](https://arxiv.org/pdf/2305.02765)
14. Self-Supervised Learning with Random-Projection Quantizer for Speech Recognition [Paper](https://arxiv.org/pdf/2202.01855)
15. Taming Transformers for High-Resolution Image Synthesis [Paper](https://arxiv.org/pdf/2012.09841)
16. Finite Scalar Quantization: VQ-VAE Made Simple [Paper](https://arxiv.org/abs/2309.15505)


## Image Generator

1. DiVAE : Photorealistic Images Synthesis with Denoising Diffusion Decoder [Paper](https://arxiv.org/pdf/2206.00386)
2. Vector Quantized Diffusion Model for Text-to-Image Synthesis [Paper](https://arxiv.org/pdf/2111.14822)
3. MaskGIT: Masked Generative Image Transformer [Paper](https://arxiv.org/pdf/2202.04200)
4. BEIT: BERT Pre-Training of Image Transformers [Paper](https://arxiv.org/pdf/2106.08254)
5. BEIT V2: Masked Image Modeling with Vector-Quantized Visual Tokenizers [Paper](https://arxiv.org/pdf/2208.06366)
6. MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis [Paper](https://arxiv.org/pdf/2211.09117)